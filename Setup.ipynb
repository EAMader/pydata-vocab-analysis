{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Go to\n",
    "# https://github.com/alexander-n-thomas/pydata-vocab-analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook is here to test whether everything is setup to run for the project.\n",
    "\n",
    "First, let's check the imports."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from __future__ import division, print_function\n",
    "\n",
    "import ipywidgets as widgets\n",
    "from ipywidgets import interact\n",
    "from IPython.display import clear_output, display\n",
    "\n",
    "import codecs\n",
    "from collections import Counter, defaultdict, OrderedDict\n",
    "import inspect\n",
    "from matplotlib import pyplot as plt\n",
    "import nltk\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import pickle\n",
    "from sklearn import feature_extraction as skfeatex\n",
    "from sklearn import metrics as skmetrics\n",
    "from sklearn import tree as sktree\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "import sys\n",
    "from wordcloud import WordCloud\n",
    "\n",
    "from vocab_analysis import *\n",
    "\n",
    "import answers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we check to see if the data for NLTK is installed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "stopwords = nltk.corpus.stopwords.words('english')\n",
    "sent_detector = nltk.data.load('tokenizers/punkt/english.pickle')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we check to see if all the data files are in the right place."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "if not os.path.isdir('./data'):\n",
    "    ! tar xzf vocab-ana-ws-data.tar.gz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "jobs_df = pd.read_csv('./data/job_descriptions.tsv', sep='\\t', encoding='UTF-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "jobs_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! head ./data/AntBNC_lemmas_ver_001.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open('./data/all_features.pickle') as fp:\n",
    "    all_features = pickle.load(fp)\n",
    "    assert len(all_features) == 6\n",
    "    del all_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open('./data/all_featurizers.pickle') as fp:\n",
    "    all_featurizers = pickle.load(fp)\n",
    "    assert len(all_featurizers) == 6\n",
    "    del all_featurizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open('./data/segments.pickle') as fp:\n",
    "    segments = pickle.load(fp)\n",
    "    assert len(segments) == 9\n",
    "    del segments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "if not os.path.exists('results'):\n",
    "    ! tar xzf vocab-ana-ws-results.tar.gz"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let's get started => [0. Introduction](0. Introduction.ipynb)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
