{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Vocabulary Analysis Workshop\n",
    "\n",
    "## $\\mbox{TF.IDF}$\n",
    "\n",
    "The motivation for $\\mbox{TF.IDF}$ is wanting to look at words that make documents stand out. These words are considered important for the document. If a word occurs in most documents, that may not be interesting to us. Similarly, if a word only occurs once in one document that is also not useful in summarizing our text. We want to see the words that occur often in a limited number of documents. This is why we are interested in the number of times a word occurs, and the number of documents it occurs in.\n",
    "\n",
    "$\\mbox{TF}$ stands for term frequency  \n",
    "$\\mbox{IDF}$ stands for inverse document frequency\n",
    "\n",
    "There are many flavors of $\\mbox{TF.IDF}$, let's look at one of the more common formulations.\n",
    "\n",
    "Although $\\mbox{TF}$ stands for term frequency, raw counts are often used instead. Similarly, $\\mbox{IDF}$ is often the $log$ of the inverse document frequency.\n",
    "\n",
    "Here is the mathematical definition for the flavor of $\\mbox{TF.IDF}$ we will be using.\n",
    "\n",
    "$$\n",
    "\\begin{array}{l}\n",
    "D\\ :=\\ \\text{a collection of documents}\\\\\n",
    "d\\ :=\\ \\text{a document in $D$}\\\\\n",
    "t\\ :=\\ \\text{a term}\\\\\n",
    "N\\ :=\\ |D|\\\\\n",
    "n_{t}\\ :=\\ |\\{d\\ :\\ t \\in d\\}|\\\\\n",
    "\\mbox{TF}(t, d)\\ :=\\ \\text{number of times $t$ occurs in $d$}\\\\\n",
    "\\mbox{IDF}(t)\\ :=\\ \\log_2{(1+\\frac{N}{n_{t}})}\\\\\n",
    "\\mbox{TF.IDF}(t, d)\\ :=\\ \\mbox{TF}(t, d)\\times\\mbox{IDF}(t)\\\\\n",
    "\\end{array}\n",
    "$$\n",
    "\n",
    "We will be looking at the average $\\mbox{TF.IDF}$ for words\n",
    "\n",
    "\n",
    "$$\n",
    "\\begin{align*}\n",
    "\\overline{\\mbox{TF.IDF}(t, d)}\\ &=\\ \\frac{\\sum_{d \\in D}{\\mbox{TF.IDF}(t, d)}}{N}\\\\\n",
    "&=\\ \\frac{\\sum_{d \\in D}{\\mbox{TF}(t, d)\\times\\mbox{IDF}(t)}}{N}\\\\\n",
    "&=\\ \\mbox{IDF}(t)\\times\\frac{\\sum_{d \\in D}{\\mbox{TF}(t, d)}}{N}\\\\\n",
    "\\end{align*}\n",
    "$$\n",
    "\n",
    "As one might imagine, this is still susceptible to words that have a high-enough $\\mbox{TF}$ to diminish the effect of $\\mbox{IDF}$.\n",
    "\n",
    "(tf-idf [wikipedia](https://en.wikipedia.org/wiki/Tf%E2%80%93idf))\n",
    "\n",
    "We will produce two kinds of visualizations using $\\mbox{TF.IDF}$.\n",
    "\n",
    "1. A plot of $\\mbox{TF}$ vs $\\mbox{IDF}$\n",
    "2. A word cloud, which is where we display our vocabulary with size proportional to some weight ($\\mbox{TF.IDF}$)\n",
    "\n",
    "You will sometimes here this kind of approach called to as the _bag-of-words_ approach. This is referring to how the documents are treated like _bags_. A _bag_ (AKA [_multiset_](https://en.wikipedia.org/wiki/Multiset)), in this context, is a collection of things with counts of occurrences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from __future__ import division, print_function\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "from collections import Counter, defaultdict\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from vocab_analysis import *\n",
    "\n",
    "import answers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "jobs_df = pd.read_pickle('./data/tokenized.pickle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "jobs_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def calculate_avg_tfidf(term_rows):\n",
    "    bags = term_rows.apply(Counter) # convert the documents to bags, this will calculate the TF per document per term\n",
    "    sum_tf = Counter() # this will hold the sum of the TF per term\n",
    "    df = Counter() # this will calculate the raw DF (n_t from above)\n",
    "    for bag in bags:\n",
    "        sum_tf.update(bag)\n",
    "        df.update(bag.keys())\n",
    "    sum_tf = pd.Series(sum_tf)\n",
    "    df = pd.Series(df)\n",
    "    idf = np.log2(1 + len(term_rows) / df)\n",
    "    sum_tfidf = sum_tf * idf # this will calculate the sum TF.IDF per term\n",
    "    avg_tfidf = sum_tfidf / len(term_rows)  # this will calculate the average TF.IDF per term over the documents\n",
    "    return pd.DataFrame({'sum_tf': sum_tf, 'idf': idf, 'avg_tfidf': avg_tfidf})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "avg_tfidf_df = calculate_avg_tfidf(jobs_df['tokens'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_tfidf_df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First let's look at the distribution of $\\sum_{d \\in D}{\\mbox{TF}(t, d)}$ vs $\\mbox{IDF}(t)$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_tfidf_df.sort_values('sum_tf').head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_tfidf_df.sort_values('sum_tf', ascending=False).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_tfidf_df.sort_values('idf').head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_tfidf_df.sort_values('idf', ascending=False).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_tfidf_df.sort_values('avg_tfidf').head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_tfidf_df.sort_values('avg_tfidf', ascending=False).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When searching a document, the final score is often calculated as the sum of the $\\mbox{TF.IDF}$ for each term in the query.\n",
    "\n",
    "\n",
    "$$\n",
    "\\begin{array}{l}\n",
    "D\\ :=\\ \\text{a collection of documents}\\\\\n",
    "d\\ :=\\ \\text{a document in $D$}\\\\\n",
    "q\\ :=\\ \\text{a set of terms}\n",
    "t\\ :=\\ \\text{a term}\\\\\n",
    "\\mbox{TF.IDF}(t, d)\\ :=\\ \\mbox{TF}(t, d)\\times\\mbox{IDF}(t)\\\\\n",
    "score(q, d)\\ :=\\ \\sum_{t \\in q}{\\mbox{TF.IDF}(t, d)}\n",
    "\\end{array}\n",
    "$$\n",
    "\n",
    "Let's build a function for searching our corpus.\n",
    "First, let's build our _index_ from documents to $TF$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc_index = jobs_df['tokens'].apply(Counter)\n",
    "doc_index.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we need to build an _inverted index_ from terms to documents. This will let us quickly filter to a subset of documents for calculating $TF.IDF$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inv_index = defaultdict(set)\n",
    "for ix, bag in doc_index.iteritems():\n",
    "    for term in bag:\n",
    "        inv_index[term].add(ix)\n",
    "inv_index = pd.Series(inv_index)\n",
    "inv_index.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from my_tokenize import tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def search(query, docs, doc_index, inv_index, idf, processing, limit=10):\n",
    "    terms = set(processing(query)) # always process your queries like you process your documents\n",
    "    filter_set_ixs = set()\n",
    "    term_idfs = idf[terms]\n",
    "    for term in terms:\n",
    "        filter_set_ixs |= inv_index.loc[term]\n",
    "    # we should only return documents that contain at least one word from the query\n",
    "    filter_set = doc_index.loc[filter_set_ixs]\n",
    "    tf_df = pd.DataFrame({term: filter_set.apply(lambda bag: bag[term]) for term in terms})\n",
    "    tfidf_df = tf_df * term_idfs\n",
    "    score_df = tfidf_df.apply(np.sum, axis=1).sort_values(ascending=False)\n",
    "    for doc_id, score in score_df[:limit].iteritems():\n",
    "        print('=' * 80)\n",
    "        print(doc_id)\n",
    "        print('=' * 30)\n",
    "        print(docs.loc[doc_id])\n",
    "        print('=' * 80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "search(\"data scientist\", jobs_df['description'], doc_index, inv_index, avg_tfidf_df['idf'], tokenize)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These calculation of average $TF.IDF$, and the ability to search our documents is useful, but it would be nice to be able to visualize our analysis.\n",
    "\n",
    "### NEXT => [3. Visualizing](3. Visualizing.ipynb)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
